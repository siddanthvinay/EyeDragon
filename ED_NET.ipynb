{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09DARGh2Zq8R"
      },
      "source": [
        "# Importing necessary libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmohahuhzfiS"
      },
      "outputs": [],
      "source": [
        "#run this cell to import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import itertools\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import glob\n",
        "import json\n",
        "\n",
        "!pip install -U pillow\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, Input\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "\n",
        "from keras.utils import np_utils, normalize\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape, Dropout, Conv2DTranspose, Activation, Concatenate, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ProgbarLogger\n",
        "from keras.applications import EfficientNetB7\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "!pip install -U ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "!pip install ray[tune]\n",
        "!pip install hyperopt==0.2.5\n",
        "\n",
        "import ray\n",
        "from hyperopt import hp\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_xz6iHeN-tO",
        "outputId": "8396175d-894b-4987-a3fd-d752338bef20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 1: Preprocessing"
      ],
      "metadata": {
        "id": "W68qCeV_HV6v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahr9orJNQzgJ"
      },
      "source": [
        "#### Creating multiple functions for augmentation, each with paramenters for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcPG1RfhPxYo"
      },
      "outputs": [],
      "source": [
        "#defines functions for augmentation\n",
        "\n",
        "#modifies dimensions of the image from original using OpenCV method resize()\n",
        "def crop(img, newSize):\n",
        "  width, height, ______ = img.shape\n",
        "  if width == height:\n",
        "    return cv.resize(img, newSize)\n",
        "  length = min(width, height)\n",
        "  left = (width - length) // 2\n",
        "  top = (height - length) // 2\n",
        "  right = (width + length) // 2\n",
        "  bottom = (height + length) // 2\n",
        "  return cv.resize(img[left:right, top:bottom, :], newSize)\n",
        "\n",
        "#randomizes brightness of the image, converts to HSV and multiplies all pixels by a random brightness value\n",
        "def brightness(img, low, high):\n",
        "  value = random.uniform(low, high)\n",
        "  hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "  hsv = np.array(hsv, dtype = np.float64)\n",
        "  hsv[:,:,1] = hsv[:,:,1]*value\n",
        "  hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
        "  hsv[:,:,2] = hsv[:,:,2]*value\n",
        "  hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
        "  hsv = np.array(hsv, dtype = np.uint8)\n",
        "  img = cv.cvtColor(hsv, cv.COLOR_HSV2RGB)\n",
        "  return img\n",
        "\n",
        "#randomly flips image based on boolean value\n",
        "def horizontal_orientation(img):\n",
        "  if bool(random.getrandombits(1)):\n",
        "    return cv.flip(img)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "#rotates image based on random angle\n",
        "def rotation(img, angle):\n",
        "  angle = int(random.uniform(-angle, angle))\n",
        "  h, w = img.shape[:2]\n",
        "  M = cv.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "  img = cv.warpAffine(img, M, (w, h))\n",
        "  return img\n",
        "\n",
        "def grayscale(img):\n",
        "  img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOhLwDBCRDkO"
      },
      "source": [
        "#### Using functions on an image pathway and writing them back to save in the directory as adjusted images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq_TdEKJP6vc"
      },
      "outputs": [],
      "source": [
        "#resizes all images to be 224px by 224px, writes them back into image directory\n",
        "def resize(impath):\n",
        "  img = cv.imread(impath)\n",
        "  eq_image = crop(img, (224, 224))\n",
        "  cv.imwrite(impath, eq_image*255)\n",
        "\n",
        "#brightens all images to random value from 1 - 1.6, writes them back into image directory\n",
        "def brighten(impath):\n",
        "  img = plt.imread(impath)\n",
        "  eq_image = brightness(img, 0.8, 1.6)\n",
        "  cv.imwrite(impath, eq_image*255)\n",
        "\n",
        "#rotates all images by a degree from -180 to 180, writes them back into image directory\n",
        "def rotate(impath):\n",
        "  img = plt.imread(impath)\n",
        "  eq_image = rotation(img, 180)\n",
        "  cv.imwrite(impath, eq_image*255)\n",
        "\n",
        "#randomly flips image horizontally, writes them back into image directory\n",
        "def flip(impath):\n",
        "  img = plt.imread(impath)\n",
        "  eq_image = horizontal_orientation(img)\n",
        "  cv.imwrite(impath, eq_image*255)\n",
        "\n",
        "def gray(impath):\n",
        "  img = plt.imread(impath)\n",
        "  eq_image = grayscale(img)\n",
        "  cv.imwrite(impath, eq_image*255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsbWb2QoROUn"
      },
      "source": [
        "#### Two final functions to test any image and apply random filters on all images, then save them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnZqOYdOQyOW"
      },
      "outputs": [],
      "source": [
        "def one_aug(impath):\n",
        "  img = Image.open(impath)\n",
        "  img = img.resize((224, 224), Image.LANCZOS)\n",
        "  img.save(impath, \"PNG\" if \".png\" in impath else \"JPEG\")\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.RandomCrop(width=256, height=256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "])\n",
        "\n",
        "#images enhancement (takes a while ~3-4 min), loops through all file paths, utilizes all implementation functions\n",
        "def final_aug():\n",
        "  for folder1 in os.listdir(\"content/images_full\"):\n",
        "    for folder2 in os.listdir(\"content/images_full/\" + folder1):\n",
        "      for element in os.listdir(\"content/images_full/\" + folder1 + \"/\" + folder2):\n",
        "        element = os.path.join(\"content/images_full/\" + folder1 + \"/\" + folder2, element)\n",
        "        one_aug(element)\n",
        "\n",
        "\n",
        "#grabs random image and runs augmentation on it without writing back to directory\n",
        "def test_images(impath):\n",
        "  image = plt.imread(impath)\n",
        "  plt.imshow(crop(rotation(image, 180), (224, 224)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6myH6uCIgOE"
      },
      "source": [
        "#Section 2: Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weYSOT7TAK9V"
      },
      "outputs": [],
      "source": [
        "#adding data from drive\n",
        "!rm -rf images_full\n",
        "!unzip drive/MyDrive/images_full.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuXO_-n-YwNt"
      },
      "outputs": [],
      "source": [
        "#running augmentation on all images\n",
        "final_aug()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buaXSe2X873p"
      },
      "outputs": [],
      "source": [
        "data = 'content/images_full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2KoEspNtoZG"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters to tune\n",
        "learning_rates = [0.01]\n",
        "batch_sizes = [16, 32]\n",
        "optimizers = ['Adam']\n",
        "epochs = [1]\n",
        "\n",
        "\n",
        "# Set up the search space\n",
        "search_space = {'learning_rate': learning_rates,\n",
        "                'batch_size': batch_sizes,\n",
        "                'optimizer': optimizers,\n",
        "                'epochs': epochs}\n",
        "\n",
        "# Create parameter grid\n",
        "parameter_grid = ParameterGrid(search_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLMifgLqFRxw",
        "outputId": "583dd0e3-15cc-42bf-8c91-992f3f8721b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-cls.pt to 'yolov8x-cls.pt'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110M/110M [00:02<00:00, 39.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8x-cls.pt\")\n",
        "counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvDezTHnXNDH",
        "outputId": "10df87b7-07d4-441a-aa48-01a0f3138137"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.164 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8x-cls.pt, data=content/images_full, epochs=25, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/content/images_full/train... found 25378 images in 6 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/content/images_full/test... found 2566 images in 6 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n",
            "  8                  -1  3  27865600  ultralytics.nn.modules.block.C2f             [1280, 1280, 3, True]         \n",
            "  9                  -1  1   1648646  ultralytics.nn.modules.head.Classify         [1280, 6]                     \n",
            "YOLOv8x-cls summary: 183 layers, 56149526 parameters, 56149526 gradients\n",
            "Transferred 300/302 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/content/images_full/train... 25378 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25378/25378 [00:07<00:00, 3248.95it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/content/images_full/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/content/images_full/test... 2566 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2566/2566 [00:00<00:00, 3181.75it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/content/images_full/test.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/25         0G     0.5285         16        224:   0%|          | 1/1587 [00:25<11:20:15, 25.73s/it]Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 14.7MB/s]\n",
            "       1/25         0G     0.3398         16        224:  22%|â–ˆâ–ˆâ–       | 356/1587 [2:14:31<7:42:25, 22.54s/it]"
          ]
        }
      ],
      "source": [
        "model.train(data=\"content/images_full\", imgsz=224, epochs=25, optimizer=\"SGD\", batch=16, cos_lr = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTjQU0KjW8xS",
        "outputId": "4649ea05-aae3-4671-adf6-2a55a8536b85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.164 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=content/images_full, epochs=1, patience=10, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/content/images_full/train... found 25378 images in 6 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/content/images_full/test... found 2566 images in 6 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    337926  ultralytics.nn.modules.head.Classify         [256, 6]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1445974 parameters, 1445974 gradients\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/content/images_full/train... 25378 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25378/25378 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/content/images_full/test... 2566 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2566/2566 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "        1/1         0G     0.2287          2        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1587/1587 [23:16<00:00,  1.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:45<00:00,  1.78it/s]\n",
            "                   all       0.64      0.995\n",
            "\n",
            "1 epochs completed in 0.401 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-29897766cfa2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs/classify/train'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/results.csv'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'runs/classify/train/results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mv content/runs/classify/train\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" drive/MyDrive/Trained Models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'command'"
          ]
        }
      ],
      "source": [
        "counter = 1\n",
        "!rm -rf runs/classify\n",
        "\n",
        "# Train and evaluate the model for each combination of hyperparameters\n",
        "for parameters in parameter_grid:\n",
        "    model = YOLO(\"yolov8n-cls.pt\")\n",
        "    # Set hyperparameters for the model\n",
        "    learning_rate = parameters['learning_rate']\n",
        "    batch_size = parameters['batch_size']\n",
        "    optimizer = parameters['optimizer']\n",
        "    num_epochs = parameters['epochs']\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    model.train(data=\"content/images_full\", lr0 = learning_rate, batch = batch_size, optimizer = optimizer, epochs = num_epochs, patience = 10, imgsz = 224)\n",
        "    df = pd.read_csv('runs/classify/train' + str(counter) + '/results.csv' if counter != 1 else 'runs/classify/train/results.csv')\n",
        "\n",
        "    os.system(\"mv content/runs/classify/train\" + str(counter) + \" drive/MyDrive/Trained Models\")\n",
        "\n",
        "    # Save the results\n",
        "    result = {'learning_rate': learning_rate,\n",
        "              'batch_size': batch_size,\n",
        "              'optimizer': optimizer,\n",
        "              'num_epochs': num_epochs,\n",
        "              'accuracy': pd.Series(df['  metrics/accuracy_top1']).tolist(),\n",
        "              'val/loss': df['               val/loss'].tolist()}\n",
        "\n",
        "    if counter == 1:\n",
        "      file = open('runs/classify/train/hyperparameters.json', 'w')\n",
        "    else:\n",
        "      file = open('runs/classify/train' + str(counter) + '/hyperparameters.json', 'w')\n",
        "    file.write(json.dumps(result))\n",
        "    file.close()\n",
        "\n",
        "    counter+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2749Sn7ya6-Z"
      },
      "outputs": [],
      "source": [
        "# new_df = pd.DataFrame(columns = ['learning_rate', 'batch_size', 'optimizer', 'num_epochs', 'accuracy', 'val/loss'])\n",
        "# !rm -rf runs/classify/train5\n",
        "\n",
        "# for folder in os.listdir('runs/classify'):\n",
        "#   file = open('runs/classify/' + folder + '/hyperparameters.json', 'r')\n",
        "#   hyperparameters = json.loads(file.read())\n",
        "#   new_df.loc[len(new_df)] = [hyperparameters['learning_rate'], hyperparameters['batch_size'], hyperparameters['optimizer'], hyperparameters['num_epochs'], hyperparameters['accuracy'], hyperparameters['val/loss']]\n",
        "#   file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJR-0GE_RIjz"
      },
      "outputs": [],
      "source": [
        "# new_df.to_csv('drive/MyDrive/HYPERPARAMETERS.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt4RClstVnom"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}